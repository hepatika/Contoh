{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "nyoba transfer learning GoogleNet",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFzZcG653q7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "1357462c-640a-48a3-b250-2d6bd11f3b5f"
      },
      "source": [
        "#import libraries\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.layers import Activation, Dense, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam,RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import pandas as pd\n",
        "import os.path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ-nMdPQfY6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "31e2ba5b-58b4-4d99-a07b-ec744437e9f8"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBU8LFknfv6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f24db003-e6ac-42a4-ddaf-520493a33083"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odAQUvzE4B0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "9aad2231-75e4-4ae5-8e14-f36d570eb177"
      },
      "source": [
        "os.listdir('gdrive/My Drive/Colab Notebooks/Pre-Trained/vgg19/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['testing2',\n",
              " 'train',\n",
              " 'models',\n",
              " 'models2',\n",
              " 'models3',\n",
              " 'models4',\n",
              " 'models5',\n",
              " 'freeze']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pUFIp4i4G4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = OneHotEncoder()\n",
        "enc.fit([[0], [1], [2]]) \n",
        "def names(number):\n",
        "    if(number == 0):\n",
        "        return 'Abnormal Leukemia'\n",
        "    elif(number== 1):\n",
        "        return 'Normal Leukemia'\n",
        "    else:\n",
        "        return 'Normal'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUtMZDkf4e7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61513991-c07d-4085-e24d-0012795c940e"
      },
      "source": [
        "data = []\n",
        "paths = []\n",
        "ans = []\n",
        "for r, d, f in os.walk('gdrive/My Drive/Colab Notebooks/cnn/train-skenario2/abnormal100'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    x = img.resize((224, 224,))\n",
        "    x = np.array(x)\n",
        "    if(x.shape == (224,224,3)):\n",
        "        data.append(np.array(x))\n",
        "        ans.append(enc.transform([[0]]).toarray())\n",
        "\n",
        "len(ans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSOtty_G5NTc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e7192b9-b89b-4155-db39-04cdb3cc0255"
      },
      "source": [
        "paths = []\n",
        "for r, d, f in os.walk('gdrive/My Drive/Colab Notebooks/cnn/train-skenario2/normal_leukemia100'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    x = img.resize((224,224))\n",
        "    x = np.array(x)\n",
        "    if(x.shape == (224,224,3)):\n",
        "        data.append(np.array(x))\n",
        "        ans.append(enc.transform([[1]]).toarray())\n",
        "        \n",
        "len(ans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v7sIyfv5O5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b1cb7134-0b90-4401-99af-0ec24c3773ef"
      },
      "source": [
        "paths = []\n",
        "for r, d, f in os.walk('gdrive/My Drive/Colab Notebooks/cnn/train-skenario2/normal_noncancer100'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    x = img.resize((224,224))\n",
        "    x = np.array(x)\n",
        "    if(x.shape == (224,224,3)):\n",
        "        data.append(np.array(x))\n",
        "        ans.append(enc.transform([[2]]).toarray())\n",
        "        \n",
        "len(ans)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKinrrBh5WF3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5d7a8ce-8f58-4d7a-eb51-4e9afd486c60"
      },
      "source": [
        "data = np.array(data)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlhJp4aA5aCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = np.array(ans)\n",
        "ans = ans.reshape(len(ans),3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sfW-eTs_27G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc2 = OneHotEncoder()\n",
        "enc2.fit([[0], [1], [2]]) \n",
        "def names(number):\n",
        "    if(number == 0):\n",
        "        return 'Abnormal Leukemia'\n",
        "    elif(number== 1):\n",
        "        return 'Normal Leukemia'\n",
        "    else:\n",
        "        return 'Normal'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJvVPzDHANAw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15cbf1fd-9262-4805-ade2-ffcdc041350b"
      },
      "source": [
        "data2 = []\n",
        "paths2 = []\n",
        "ans2 = []\n",
        "for s, n, z in os.walk('gdrive/My Drive/Colab Notebooks/Pre-Trained/vgg19/testing2/abnormal'):\n",
        "    for file in z:\n",
        "        if '.jpg' in file:\n",
        "            paths2.append(os.path.join(s, file))\n",
        "\n",
        "for path in paths2:\n",
        "    img = Image.open(path)\n",
        "    x = img.resize((224,224))\n",
        "    x = np.array(x)\n",
        "    if(x.shape == (224,224, 3)):\n",
        "        data2.append(np.array(x))\n",
        "        ans2.append(enc2.transform([[0]]).toarray())\n",
        "\n",
        "len(ans2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eXMVrrQmGjJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3c5e2c8e-17c0-4035-bc50-6a782240b2aa"
      },
      "source": [
        "paths2 = []\n",
        "for s, n, z in os.walk('gdrive/My Drive/Colab Notebooks/Pre-Trained/vgg19/testing2/normal_leukemia'):\n",
        "    for file in z:\n",
        "        if '.jpg' in file:\n",
        "            paths2.append(os.path.join(s, file))\n",
        "\n",
        "for path in paths2:\n",
        "    img = Image.open(path)\n",
        "    x = img.resize((224,224))\n",
        "    x = np.array(x)\n",
        "    if(x.shape == (224,224,3)):\n",
        "        data2.append(np.array(x))\n",
        "        ans2.append(enc2.transform([[1]]).toarray())\n",
        "\n",
        "len(ans2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqooBalGmOEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16f1db9a-6fab-42fc-89c4-c5e41cef8751"
      },
      "source": [
        "paths2 = []\n",
        "for s, n, z in os.walk('gdrive/My Drive/Colab Notebooks/Pre-Trained/vgg19/testing2/normal_noncancer'):\n",
        "    for file in z:\n",
        "        if '.jpg' in file:\n",
        "            paths2.append(os.path.join(s, file))\n",
        "\n",
        "for path in paths2:\n",
        "    img = Image.open(path)\n",
        "    x = img.resize((224,224))\n",
        "    x = np.array(x)\n",
        "    if(x.shape == (224,224,3)):\n",
        "        data2.append(np.array(x))\n",
        "        ans2.append(enc2.transform([[2]]).toarray())\n",
        "\n",
        "len(ans2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOvTW3UqmVxc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c1c80766-bc4d-4491-8c0f-5893de373760"
      },
      "source": [
        "data2 = np.array(data2)\n",
        "data2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCbRuv49mYjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans2 = np.array(ans2)\n",
        "ans2 = ans2.reshape(len(ans2),3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi4pCIVomeFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_train,x_val,y_train,y_val = train_test_split(data, ans, test_size=0.2, shuffle=True, random_state=2)\n",
        "best_score = 0.0\n",
        "best_fold_index=0\n",
        "i=0\n",
        "# input_shape= ( 224, 224, 3 )\n",
        "fold_history = []\n",
        "index = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwR_Q4A2m0a5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "992c8ee8-527a-49c6-8a0a-7d3db36f3bd7"
      },
      "source": [
        "from keras.applications import inception_v3\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input as inception_v3_preprocessor\n",
        "\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Get the InceptionV3 model so we can do transfer learning\n",
        "base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(224, 224, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BOc3X27m6PA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Psmc7cgm_wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add a fully-connected layer and a logistic layer with 3 classes\n",
        "# x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(3, activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTVk9JS85nNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The model we will train\n",
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Iag6vp5vW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first: train only the top layers i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers[:8]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_QKd5PmnL3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af96c8e3-fc24-4245-e5f6-6669653e6a54"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 3)            6147        global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 21,808,931\n",
            "Trainable params: 21,745,923\n",
            "Non-trainable params: 63,008\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI6JOg3CnRZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile the model\n",
        "opt = Adam(lr=0.0003)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC9GDLJEnloa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c621fc8-9e91-475f-994d-3fbea73cb141"
      },
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
        "\n",
        "Y_non_one_hot = np.array([np.where(r == 1)[0][0] for r in ans])\n",
        "for index, (train_indices, val_indices) in enumerate(skf.split(data, Y_non_one_hot)):\n",
        "    # print(\"Ini fold ke {}\".format(index + 1))\n",
        "    # print(train_indices)\n",
        "    X_train_cv = data[train_indices]\n",
        "    X_val_cv = data[val_indices]\n",
        "    Y_train_cv = ans[train_indices]\n",
        "    Y_val_cv = ans[val_indices]\n",
        "    \n",
        "    data_split = {'X_train': X_train_cv, 'X_val': X_val_cv, 'Y_train': Y_train_cv,\n",
        "                  'Y_val': Y_val_cv, 'train_index': train_indices, 'val_index': val_indices}\n",
        "    model_path = \"gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/\"\n",
        "    \n",
        "    if not os.path.exists(model_path):\n",
        "      os.makedirs(model_path)\n",
        "    filepath = model_path + \\\n",
        "          \"fold_{}_\".format(index + 1) + \\\n",
        "          \"epochs-{epoch:03d}-val_acc-{val_acc:.3f}.hdf5\"\n",
        "    filepath2 = model_path + \"best_weight_fold_{}.hdf5\".format(index + 1)\n",
        "    early_stopping = EarlyStopping(monitor='val_acc', patience=10, verbose=1, restore_best_weights=True)\n",
        "\n",
        "    epoch_awal = 0\n",
        "    epoch_akhir =10\n",
        "    early_stopping = EarlyStopping(monitor='val_acc', patience=10, verbose=1, restore_best_weights=True)\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='loss', save_weights_only=True, verbose=1, save_best_only=True, mode='min')\n",
        "    checkpoint2 = ModelCheckpoint(filepath2, monitor='loss', save_weights_only=True, verbose=1, save_best_only=True, mode='min')\n",
        "    callbacks_list = [checkpoint, early_stopping, checkpoint2]\n",
        "\n",
        "    history = model.fit(X_train_cv, Y_train_cv, batch_size=8, initial_epoch=epoch_awal,\n",
        "                        epochs=epoch_akhir, verbose=1, validation_data=(X_val_cv, Y_val_cv), callbacks=callbacks_list)\n",
        "                    \n",
        "    fold_history.append(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 240 samples, validate on 60 samples\n",
            "Epoch 1/10\n",
            "240/240 [==============================] - 8s 35ms/step - loss: 0.2956 - acc: 0.9125 - val_loss: 1462.3563 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.29562, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_1_epochs-001-val_acc-0.333.hdf5\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.29562, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_1.hdf5\n",
            "Epoch 2/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0539 - acc: 0.9792 - val_loss: 666.3854 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00002: loss improved from 0.29562 to 0.05386, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_1_epochs-002-val_acc-0.333.hdf5\n",
            "\n",
            "Epoch 00002: loss improved from 0.29562 to 0.05386, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_1.hdf5\n",
            "Epoch 3/10\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.0269 - acc: 0.9833 - val_loss: 366.2814 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00003: loss improved from 0.05386 to 0.02687, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_1_epochs-003-val_acc-0.333.hdf5\n",
            "\n",
            "Epoch 00003: loss improved from 0.05386 to 0.02687, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_1.hdf5\n",
            "Epoch 4/10\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 0.0922 - acc: 0.9792 - val_loss: 279.2910 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.02687\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.02687\n",
            "Epoch 5/10\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.0289 - acc: 0.9958 - val_loss: 40.8901 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.02687\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.02687\n",
            "Epoch 6/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.1303 - acc: 0.9667 - val_loss: 105.8416 - val_acc: 0.5833\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.02687\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.02687\n",
            "Epoch 7/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0918 - acc: 0.9583 - val_loss: 211.9961 - val_acc: 0.5833\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.02687\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.02687\n",
            "Epoch 8/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.1068 - acc: 0.9625 - val_loss: 108.6944 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.02687\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.02687\n",
            "Epoch 9/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.1377 - acc: 0.9542 - val_loss: 498.9621 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.02687\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.02687\n",
            "Epoch 10/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0206 - acc: 0.9958 - val_loss: 310.1441 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00010: loss improved from 0.02687 to 0.02061, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_1_epochs-010-val_acc-0.333.hdf5\n",
            "\n",
            "Epoch 00010: loss improved from 0.02687 to 0.02061, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_1.hdf5\n",
            "Train on 240 samples, validate on 60 samples\n",
            "Epoch 1/10\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 0.1310 - acc: 0.9417 - val_loss: 41.4672 - val_acc: 0.2833\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.13104, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_2_epochs-001-val_acc-0.283.hdf5\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.13104, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_2.hdf5\n",
            "Epoch 2/10\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.0457 - acc: 0.9833 - val_loss: 329.9994 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00002: loss improved from 0.13104 to 0.04568, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_2_epochs-002-val_acc-0.333.hdf5\n",
            "\n",
            "Epoch 00002: loss improved from 0.13104 to 0.04568, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_2.hdf5\n",
            "Epoch 3/10\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 0.0986 - acc: 0.9625 - val_loss: 236.1216 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.04568\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.04568\n",
            "Epoch 4/10\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.0225 - acc: 0.9875 - val_loss: 434.0691 - val_acc: 0.6167\n",
            "\n",
            "Epoch 00004: loss improved from 0.04568 to 0.02249, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_2_epochs-004-val_acc-0.617.hdf5\n",
            "\n",
            "Epoch 00004: loss improved from 0.04568 to 0.02249, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_2.hdf5\n",
            "Epoch 5/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.1069 - acc: 0.9708 - val_loss: 204.3192 - val_acc: 0.5667\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.02249\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.02249\n",
            "Epoch 6/10\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.1213 - acc: 0.9625 - val_loss: 69.1637 - val_acc: 0.4333\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.02249\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.02249\n",
            "Epoch 7/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0516 - acc: 0.9792 - val_loss: 29.0337 - val_acc: 0.4000\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.02249\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.02249\n",
            "Epoch 8/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.1215 - acc: 0.9625 - val_loss: 28.3020 - val_acc: 0.4167\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.02249\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.02249\n",
            "Epoch 9/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0374 - acc: 0.9875 - val_loss: 52.4492 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.02249\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.02249\n",
            "Epoch 10/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0575 - acc: 0.9792 - val_loss: 107.7551 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.02249\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.02249\n",
            "Train on 240 samples, validate on 60 samples\n",
            "Epoch 1/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0176 - acc: 0.9917 - val_loss: 126.4090 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.01759, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_3_epochs-001-val_acc-0.333.hdf5\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.01759, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_3.hdf5\n",
            "Epoch 2/10\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 0.0125 - acc: 0.9958 - val_loss: 128.4407 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00002: loss improved from 0.01759 to 0.01254, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_3_epochs-002-val_acc-0.333.hdf5\n",
            "\n",
            "Epoch 00002: loss improved from 0.01759 to 0.01254, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_3.hdf5\n",
            "Epoch 3/10\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 0.0315 - acc: 0.9875 - val_loss: 186.7037 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.01254\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.01254\n",
            "Epoch 4/10\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.0480 - acc: 0.9833 - val_loss: 291.0474 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.01254\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.01254\n",
            "Epoch 5/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0134 - acc: 0.9958 - val_loss: 389.7927 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.01254\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.01254\n",
            "Epoch 6/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0469 - acc: 0.9833 - val_loss: 73.1877 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.01254\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.01254\n",
            "Epoch 7/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0589 - acc: 0.9792 - val_loss: 56.4783 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.01254\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.01254\n",
            "Epoch 8/10\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 0.0618 - acc: 0.9833 - val_loss: 69.7947 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.01254\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.01254\n",
            "Epoch 9/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0305 - acc: 0.9917 - val_loss: 117.7867 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.01254\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.01254\n",
            "Epoch 10/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0217 - acc: 0.9917 - val_loss: 81.7763 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.01254\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.01254\n",
            "Train on 240 samples, validate on 60 samples\n",
            "Epoch 1/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0203 - acc: 0.9958 - val_loss: 81.0359 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.02029, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_4_epochs-001-val_acc-0.333.hdf5\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.02029, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_4.hdf5\n",
            "Epoch 2/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 86.4988 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00002: loss improved from 0.02029 to 0.00203, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_4_epochs-002-val_acc-0.333.hdf5\n",
            "\n",
            "Epoch 00002: loss improved from 0.02029 to 0.00203, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_4.hdf5\n",
            "Epoch 3/10\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 9.1958e-04 - acc: 1.0000 - val_loss: 91.2205 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00003: loss improved from 0.00203 to 0.00092, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_4_epochs-003-val_acc-0.333.hdf5\n",
            "\n",
            "Epoch 00003: loss improved from 0.00203 to 0.00092, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_4.hdf5\n",
            "Epoch 4/10\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.0206 - acc: 0.9917 - val_loss: 182.8474 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.00092\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.00092\n",
            "Epoch 5/10\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 0.0096 - acc: 0.9958 - val_loss: 173.4702 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.00092\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.00092\n",
            "Epoch 6/10\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.0090 - acc: 0.9958 - val_loss: 215.6847 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.00092\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.00092\n",
            "Epoch 7/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 163.7723 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.00092\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.00092\n",
            "Epoch 8/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 130.6565 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.00092\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.00092\n",
            "Epoch 9/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 157.8614 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.00092\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.00092\n",
            "Epoch 10/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 212.1108 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.00092\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.00092\n",
            "Train on 240 samples, validate on 60 samples\n",
            "Epoch 1/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0088 - acc: 0.9958 - val_loss: 363.6606 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.00883, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_5_epochs-001-val_acc-0.333.hdf5\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.00883, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_5.hdf5\n",
            "Epoch 2/10\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 0.0567 - acc: 0.9833 - val_loss: 479.6738 - val_acc: 0.3500\n",
            "\n",
            "Epoch 00002: loss did not improve from 0.00883\n",
            "\n",
            "Epoch 00002: loss did not improve from 0.00883\n",
            "Epoch 3/10\n",
            "240/240 [==============================] - 6s 23ms/step - loss: 0.0478 - acc: 0.9792 - val_loss: 1069.2905 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.00883\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.00883\n",
            "Epoch 4/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0754 - acc: 0.9750 - val_loss: 148.0565 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.00883\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.00883\n",
            "Epoch 5/10\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.0605 - acc: 0.9833 - val_loss: 120.9311 - val_acc: 0.3500\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.00883\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.00883\n",
            "Epoch 6/10\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.0530 - acc: 0.9833 - val_loss: 95.6734 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.00883\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.00883\n",
            "Epoch 7/10\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.0268 - acc: 0.9875 - val_loss: 387.1288 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.00883\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.00883\n",
            "Epoch 8/10\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.0402 - acc: 0.9875 - val_loss: 525.8507 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.00883\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.00883\n",
            "Epoch 9/10\n",
            "240/240 [==============================] - 5s 23ms/step - loss: 0.0137 - acc: 0.9958 - val_loss: 485.3167 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.00883\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.00883\n",
            "Epoch 10/10\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 389.8800 - val_acc: 0.3333\n",
            "\n",
            "Epoch 00010: loss improved from 0.00883 to 0.00473, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/fold_5_epochs-010-val_acc-0.333.hdf5\n",
            "\n",
            "Epoch 00010: loss improved from 0.00883 to 0.00473, saving model to gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_5.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m3FMgZgqqxS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0ee3452a-3f51-4cff-f25a-cf320c93aef3"
      },
      "source": [
        "# model_path = \"gdrive/My Drive/Colab Notebooks/cnn/tanpa-kfold/model1000/nyoba5/\"\n",
        "print(\"Best Fold\", best_fold_index + 1)\n",
        "best_weight = model_path + \"best_weight_fold_{}.hdf5\".format(best_fold_index + 1)\n",
        "# best_weight = model_path + \"best_weight_fold_1.hdf5\"\n",
        "print(\"best_weight\", best_weight)\n",
        "\n",
        "# model = cnn2()\n",
        "model.load_weights(best_weight)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics= ['acc'])\n",
        "test_scores = model.evaluate(data2, ans2, verbose=1)\n",
        "# print(\"CNN Loss: %.2f%%\" % (100-scores[1]*100))\n",
        "# print(\"CNN Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "print(\"CNN loss: %.2f%%\" % (100 - test_scores[1] * 100))\n",
        "print(\"trained model directly, accuracy: {:5.2f}%\".format(test_scores[1] * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Fold 1\n",
            "best_weight gdrive/My Drive/Colab Notebooks/Pre-Trained/InceptionV3/freeze/model4/best_weight_fold_1.hdf5\n",
            "9/9 [==============================] - 1s 108ms/step\n",
            "CNN loss: 66.67%\n",
            "trained model directly, accuracy: 33.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyALVFqksFX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "7d2bf2ee-925d-486e-b3c6-cb2b4d7bc868"
      },
      "source": [
        "#print classification report\n",
        "from sklearn import metrics\n",
        "from imblearn.metrics import sensitivity_specificity_support\n",
        "\n",
        "true_labels = ['Abnormal','Normal Leukemia','Normal Noncancer']\n",
        "labels = [0,1,2]\n",
        "Y_pred = model.predict(data2, batch_size=data2.shape[0])\n",
        "preds = np.argmax(Y_pred, axis=1)\n",
        "y_test_non_one_hot = np.argmax(ans2, axis=1)\n",
        "\n",
        "# Save variable\n",
        "acc = metrics.accuracy_score(y_test_non_one_hot, preds)\n",
        "cm = metrics.confusion_matrix(y_test_non_one_hot, preds, labels)\n",
        "f1 = metrics.f1_score(y_test_non_one_hot, preds, average='micro')\n",
        "precision = metrics.precision_score(y_test_non_one_hot, preds, average='micro')\n",
        "recall = metrics.recall_score(y_test_non_one_hot, preds, average='micro')\n",
        "# sens_mac = sensitivity_specificity_support(ans2, Y_pred, average='macro')\n",
        "# sens_mic = sensitivity_specificity_support(ans2, Y_pred, average='micro')\n",
        "# sens_weight = sensitivity_specificity_support(ans2, Y_pred, average='weighted')\n",
        "classification_report = metrics.classification_report(y_test_non_one_hot, preds,labels=labels,target_names=true_labels) \n",
        "print(\"Accuracy\", acc)\n",
        "print(\"Precision\", precision)\n",
        "print(\"Recall\", recall)\n",
        "print(\"F1-score\", f1)\n",
        "# print(\"Sensitivity Specificity Macro\", sens_mac)\n",
        "# print(\"Sensitivity Specificity Micro\", sens_mic)\n",
        "# print(\"Sensitivity Specificity Weighted\", sens_weight)\n",
        "print(classification_report)\n",
        "\n",
        "print(\"Confusion Matrix\")\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.3333333333333333\n",
            "Precision 0.3333333333333333\n",
            "Recall 0.3333333333333333\n",
            "F1-score 0.3333333333333333\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        Abnormal       0.00      0.00      0.00         3\n",
            " Normal Leukemia       0.33      1.00      0.50         3\n",
            "Normal Noncancer       0.00      0.00      0.00         3\n",
            "\n",
            "        accuracy                           0.33         9\n",
            "       macro avg       0.11      0.33      0.17         9\n",
            "    weighted avg       0.11      0.33      0.17         9\n",
            "\n",
            "Confusion Matrix\n",
            "[[0 3 0]\n",
            " [0 3 0]\n",
            " [0 3 0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D9-_swHtiss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f954ae86-20d7-479f-8e27-edde059b5248"
      },
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "           \n",
        "fig, ax = plot_confusion_matrix(conf_mat=cm,\n",
        "                                colorbar=True,\n",
        "                                show_absolute=True,\n",
        "                                show_normed=False)\n",
        "plt.show()\n",
        "# plt.savefig('gdrive/My Drive/Colab Notebooks/cnn/model_data1000/cm-.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAEKCAYAAABzM8J8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZvklEQVR4nO3de5RdZZ3m8e9zqhJAw20MPUAlkJAgdAURNBAus3rRoiEJAj3d0CTOIIhtRhoHmBano9I4snotgtiwpKHFIDSISCIXm8uAEZXFrSUXIoRcuJRcJJUsNdgTAgZiit/8cXbBoag6Z29yTu19dj0f1l45l13v/tVeycO7L++7FRGYmZVFJe8CzMyayaFmZqXiUDOzUnGomVmpONTMrFQcamZWKg41M8uFpB0lLZX0hKTVkr4+yDo7SFokqUfSEkkTGrXrUDOzvLwBfCwiPgwcAsyQdMSAdT4L/EdETAYuBy5p1KhDzcxyEVWvJm9HJcvA0QAnATckr28FjpWkeu12NrXK7aTOnUKjd867jMI69E/3ybsEa3MvvvgCGzdurBsKjXTssm/Eti2p1o0tv1sNvF7z0YKIWND/RlIH8BgwGbgqIpYMaKILeAkgIrZJ2gR8ANg41DaLFWqjd2aHA/467zIK65ElV+ZdgrW5o6dN3e42YtuW1P9OX3/8qtcjYsiNRkQfcIik3YAfSTooIlZtT30+/DSzjASqpFtSioj/B9wPzBjwVS8wHkBSJ7Ar8HK9thxqZpaNgEpHuqVeM9IeSQ8NSTsBnwCeGrDancDpyeuTgZ9Hg1k4CnX4aWZtov65+rT2Am5IzqtVgB9GxN2SLgKWR8SdwLXAjZJ6gN8Dsxs16lAzs4yU6dByKBGxEjh0kM8vrHn9OnBKlnYdamaWXXN6ai3hUDOzbERTemqt4lAzs4zknpqZlUyDK5t5cqiZWUbNuVDQKg41M8tG+PDTzErGPTUzKw8ffppZmQjo8IUCMysTn1Mzs/Lw4aeZlY17amZWKu6pmVlpyMOkzKxsPEzKzMrDFwrMrGx8+GlmpeH51MysXHz4aWZl4wsFZlYqPqdmZqUhH36aWdm4p2ZmZSKHmpmVRXU2b4eamZWFhCrFDbXinu3LyQ6jO3noxvNZsmgej936VS74/Ky8Syqknyz+MQdPOYApB07m0m/Mz7ucwin7/pGUaslDS0NN0gxJT0vqkTSvldtqlje2bmPG3CuYdup8ps2+mOlHdXP4hybkXVah9PX1cd45Z3PHXffyy5VruGXhzaxdsybvsgpjJOyfZoSapPGS7pe0RtJqSecOss4xkjZJejxZLmxUW8tCTVIHcBUwE+gG5kjqbtX2mum1LVsBGNXZQWdnBxGRc0XFsmzpUiZNmszE/fZj9OjRnHLqbO6+6468yyqMkbB/mtRT2wZ8MSK6gSOAs4fIiIci4pBkuahRo63sqR0O9ETEcxGxFVgInNTC7TVNpSIeXTiPX/9sPj9/9CmWrXox75IKZf36XsaNG//W+66ucfT29uZYUbGUfv8ow1JHRGyIiBXJ683AWqBre8trZah1AS/VvF9HEwoeDm++GRwxez6Tj7uAqQftS/ekvfIuyawwRLpeWpZzapImAIcCSwb5+khJT0i6V9KURm3lfqFA0lxJyyUtj21b8i7nHTa9uoUHlj/D9KPa4qh52Oy9dxfr1r39/6ve3nV0dbXF/6+GxUjYP5VKJdUCjO3/950scwe2JWkMcBtwXkS8MuDrFcC+EfFh4J+Bf2tY2/b/ekPqBcbXvB+XfPYOEbEgIqZGxFR17tTCctIZu/sYdh1TrWPHHUZx7LQDefqF3+RcVbFMPewwenqe5YXnn2fr1q3csmghx3/yxLzLKoyRsH8y9NQ29v/7TpYFA9oZRTXQboqI2wduJyJeiYhXk9f3AKMkja1XWyvvU1sG7C9pItUwmw18qoXba4o9x+7CNRedRkelQqUibrtvBfc+tCrvsgqls7OTy791JSccfxx9fX2cfsaZdE9peFQwYpR+/6Q4X5aqmWrqXQusjYjLhlhnT+A3ERGSDqfaEXu5XrstC7WI2CbpC8BioAO4LiJWt2p7zbLq2fUcOeeSvMsovBkzZzFjpu/hG0rZ90+T7kE7GjgNeFLS48lnXwH2AYiIq4GTgbMkbQO2ALOjwe0ILR1RkHQX72nlNsxsePVfKNheEfEwDfp8EXElcGWWdj1MyswyK/IwKYeamWUjD2g3s5JxqJlZqTjUzKw0mnWhoFUcamaWXXEzzaFmZhmJ/iFQheRQM7PMfPhpZuVS3ExzqJlZdu6pmVlp5Pn8gTQcamaWmUPNzErFYz/NrFTcUzOz8vCAdjMrEwEFzjSHmpll5aufZlYyFV8oMLPSkA8/zaxEhHtqZlYy7qmZWan4QoGZlYfPqZlZmQh5kkgzKxf31MysVHxOzczKw+fUzKxMqmM/i5tqxT3bZ2aFJaVb6reh8ZLul7RG0mpJ5w6yjiRdIalH0kpJH2lUm3tqZpZZk0YUbAO+GBErJO0MPCbpvohYU7POTGD/ZJkGfDv5c+jamlGZmY0gevs5BY2WeiJiQ0SsSF5vBtYCXQNWOwn4XlQ9Cuwmaa967bqnZmaZZJxPbayk5TXvF0TEgne1KU0ADgWWDPiqC3ip5v265LMNQ23QoWZmGWWaT21jREyt25o0BrgNOC8iXtne6hxqZpZZsy5+ShpFNdBuiojbB1mlFxhf835c8tmQfE7NzLJR9UJBmqVuM9Xu3rXA2oi4bIjV7gQ+nVwFPQLYFBFDHnqCe2pmllET71M7GjgNeFLS48lnXwH2AYiIq4F7gFlAD/AH4DONGnWomVlmzQi1iHiYakbWWyeAs7O061Azs8wKPKDAoWZm2RV5mJRDzcyy8YB2MyuT6iSRxU01h5qZZVYpcFfNoWZmmRU40xxqZpaN5AsFZlYyBT6l5lAzs+za8kKBpM1A9L9N/ozkdUTELi2uzcwKSFSvgBbVkKEWETsPZyFm1j4K3FFLN0uHpP8i6TPJ67GSJra2LDMrrJSz3uZ1MaHhOTVJXwOmAgcA/wqMBr5PdYS9mY1ABb74mepCwX+lOs1u/1zi65OHJJjZCCTa/+bbrRERkgJA0vtbXJOZFVyRr36mOaf2Q0nfofoUl88BPwWuaW1ZZlZUaZ/5mVdnrmFPLSK+KekTwCvAB4ELI+K+lldmZoXV7oefAE8CO1G9T+3J1pVjZu2guJGW4vBT0t8AS4G/BE4GHpV0ZqsLM7PiautbOoAvAYdGxMsAkj4A/DtwXSsLM7Niql79zLuKoaUJtZeBzTXvNyefmdlIpDadJFLS3yUve4Alku6gek7tJGDlMNRmZgXVrlMP9d9g+6tk6XdH68oxs6Jr28PPiPj6cBZiZu2jXXtqAEjaA/jfwBRgx/7PI+JjLazLzAqsuJGWbkTBTcBTwETg68ALwLIW1mRmBSZBR0WpljykCbUPRMS1wB8j4oGIOBMobS9th9GdPHTj+SxZNI/Hbv0qF3x+Vt4lFdJPFv+Yg6ccwJQDJ3PpN+bnXU7hlH3/FPk+tTSh9sfkzw2Sjpd0KPCfGv2QpOsk/VbSqu2qcJi9sXUbM+ZewbRT5zNt9sVMP6qbwz80Ie+yCqWvr4/zzjmbO+66l1+uXMMtC29m7Zo1eZdVGCNh/zRr7GejnJB0jKRNkh5PlgsbtZkm1P5R0q7AF4Hzge8C/yvFz10PzEixXuG8tmUrAKM6O+js7CAiGvzEyLJs6VImTZrMxP32Y/To0Zxy6mzuvssXxfuVff8IUVG6JYXraZwTD0XEIclyUaMG0wxovzt5uQn484Ylvv1zD0qakHb9IqlUxL//4O+ZNH4PvrPoQZatejHvkgpl/fpexo0b/9b7rq5xLF26JMeKiqX0+6eJM3C0Iifq3Xz7z7z94JXBijmnGQVImgvMBWDUmGY0ud3efDM4YvZ8dh2zE4su+xzdk/Ziza825F2WWWFkOF82VtLymvcLImJBxs0dKekJYD1wfkSsrrdyvZ7a8jrfNU3yCy4AqLzvTwp1nLfp1S08sPwZph/V7VCrsffeXaxb99Jb73t719HV1ZVjRcVS9v0joCN9qG2MiKnbsbkVwL4R8aqkWcC/AfvX+4F6N9/esB2FtK2xu4/hj3/sY9OrW9hxh1EcO+1A/un6n+ZdVqFMPewwenqe5YXnn2fvri5uWbSQ62/8Qd5lFcZI2D/DdbdGRLxS8/oeSf8iaWxEbBzqZ/ww4wH2HLsL11x0Gh2VCpWKuO2+Fdz7UFtdwG25zs5OLv/WlZxw/HH09fVx+hln0j1lSt5lFcZI2D/DFWqS9gR+kzxS4HCqFzfrTqjRslCTdDNwDNVj6nXA15L73Qpt1bPrOXLOJXmXUXgzZs5ixkzfwzeUMu+f6u0azUm1wXICGAUQEVdTncPxLEnbgC3A7GhwO0LLQi0i5rSqbTPLV7N6ao1yIiKuBK7M0maamW8/KOln/TfHSTpY0gVZNmJm5VLkB6+kufn2GuDLJCMLImIlMLuVRZlZcQnolFIteUhz+Pm+iFg64Bh6W4vqMbM2UOCZh1KF2kZJk0huxJV0MuCbtsxGKKUfApWLNKF2NtWbYw+U1As8D/z3llZlZoVW4ExLNfbzOeDjkt4PVCJic6OfMbNya8vpvPsNnOqj/9xamtHyZlY+gtwmgEwjzeHnazWvdwQ+CaxtTTlmVnhq855aRPxT7XtJ3wQWt6wiMys8FfgpBe9lRMH7gHHNLsTM2kPbPiKvn6QneXtetQ5gD8Dn08xGsLYONarn0Pptozpi3jffmo1gbfvcT0kdwOKIOHCY6jGzgqs+Ii/vKoZWt7SI6AOelrTPMNVjZm2giQ9eabo0h5+7A6slLaXm9o6IOLFlVZlZYbX9hQLgH1pehZm1lQKfUksVarMi4u9rP5B0CfBAa0oys2ITlQLfp5bmdN8nBvlsZrMLMbP2IIo9SWS9536eBfwtsJ+klTVf7Qw80urCzKygBJ0FPqlW7/DzB8C9wMXAvJrPN0fE71talZkVVn9PrajqPfdzE7AJ8ANUzOwd2n2SSDOzdyhwpjnUzCwbke4KY14camaWjXz4aWYlUh1R4FAzsxIpbqQ51MzsPShwR63Q5/vMrJCElG5p2JJ0naTfSlo1xPeSdIWkHkkrJX2kUZsONTPLpP/qZ5olheuBGXW+nwnsnyxzgW83atChZmaZNWs+tYh4EKg3Qukk4HtR9Siwm6S96rXpc2pmlo0yTec9VtLymvcLImJBhq11AS/VvF+XfLZhqB9wqJlZJhlvvt0YEVNbVswgHGpmltkwPnilFxhf835c8tmQfE7NzDJTyqUJ7gQ+nVwFPQLYFBFDHnqCe2pmlpGAjib11CTdDBxD9dzbOuBrwCiAiLgauAeYBfQAfwA+06hNh5qZZdaso8+IqDu1WUQEcHaWNh1qZpaRUIEHSjnUzCyzIg+TcqiZWSbVWzqKm2oONTPLJscnRaXhUDOzzDyfmpmVRnWSyLyrGJpDzcwy89VPMyuVAh99OtTMLDv31MysNHxOzczKJeUEkHlxqJlZZsWNNIeamWXk536aWekUN9Icamb2XhQ41RxqZpaZDz/NrFSKG2kONTN7Lwqcag41M8uk+lCV4qaaQ83MsvF8amZWNgXONIeamWWl4XyYcWYONTPLrMCZ5lAzs2ya+PT1lnComVl2BU41h5qZZVbkWzoqeRdQNDuM7uShG89nyaJ5PHbrV7ng87PyLqmQfrL4xxw85QCmHDiZS78xP+9yCqfs+0dKt+ShZaEmabyk+yWtkbRa0rmt2lYzvbF1GzPmXsG0U+czbfbFTD+qm8M/NCHvsgqlr6+P8845mzvuupdfrlzDLQtvZu2aNXmXVRil3z8pAy1NqEmaIelpST2S5g3y/RmSfifp8WT5m0ZttrKntg34YkR0A0cAZ0vqbuH2mua1LVsBGNXZQWdnBxGRc0XFsmzpUiZNmszE/fZj9OjRnHLqbO6+6468yyqMkbB/lPK/um1IHcBVwEygG5gzREYsiohDkuW7jWprWahFxIaIWJG83gysBbpatb1mqlTEowvn8eufzefnjz7FslUv5l1Soaxf38u4cePfet/VNY7e3t4cKyqWsu8f0bSe2uFAT0Q8FxFbgYXASdtb37CcU5M0ATgUWDIc29teb74ZHDF7PpOPu4CpB+1L96S98i7JrFCUcmmgC3ip5v06Bu/4/JWklZJulTR+kO/foeWhJmkMcBtwXkS8Msj3cyUtl7Q8tm1pdTmZbHp1Cw8sf4bpR7XFUfOw2XvvLtate/vvYm/vOrq62qITPixGxP5Jn2pj+/99J8vcjFu6C5gQEQcD9wE3NPqBloaapFFUA+2miLh9sHUiYkFETI2IqercqZXlpDJ29zHsOqZax447jOLYaQfy9Au/ybmqYpl62GH09DzLC88/z9atW7ll0UKO/+SJeZdVGCNh/1SSJ0o1WoCN/f++k2VBTTO9QG3Pa1zy2Vsi4uWIeCN5+13go41qa9l9aqoODrsWWBsRl7VqO82259hduOai0+ioVKhUxG33reDeh1blXVahdHZ2cvm3ruSE44+jr6+P0884k+4pU/IuqzBGwv5p0t0ay4D9JU2kGmazgU+9YzvSXhGxIXl7ItVz83W18ubbo4HTgCclPZ589pWIuKeF29xuq55dz5FzLsm7jMKbMXMWM2b6Hr6hlH7/NCHVImKbpC8Ai4EO4LqIWC3pImB5RNwJnCPpRKp3U/weOKNRuy0LtYh4mEIPpjCz96KZk0QmnZx7Bnx2Yc3rLwNfztKmh0mZWTaeJNLMyqbAmeZQM7OsPEmkmZVMgTPNoWZm2XiSSDMrnwKnmkPNzDIr8iSRDjUzy8zn1MysPAQVh5qZlUtxU82hZmaZ9E8SWVQONTPLrMCZ5lAzs+zcUzOzUvEwKTMrleJGmkPNzDLK80HFaTjUzCwzjygws3IpbqY51MwsuwJnmkPNzLJ66/F3heRQM7NMij6ioOVPaDczG07uqZlZZkXuqTnUzCwz39JhZuXhm2/NrEyKfqHAoWZmmfnw08xKpcg9Nd/SYWaZKeXSsB1phqSnJfVImjfI9ztIWpR8v0TShEZtOtTMLLsmpJqkDuAqYCbQDcyR1D1gtc8C/xERk4HLgUsaleZQM7NMBFSkVEsDhwM9EfFcRGwFFgInDVjnJOCG5PWtwLFqMENloc6pxZbfbXz98atezLuOGmOBjXkX0W+nUVflXcJAhdo/BVW0fbTv9jawYsVji3capbEpV99R0vKa9wsiYkHyugt4qea7dcC0AT//1joRsU3SJuAD1NmnxQq1iD3yrqGWpOURMTXvOorK+6exMu6jiJiRdw31+PDTzPLSC4yveT8u+WzQdSR1ArsCL9dr1KFmZnlZBuwvaaKk0cBs4M4B69wJnJ68Phn4eUREvUYLdfhZQAsarzKief805n00hOQc2ReAxUAHcF1ErJZ0EbA8Iu4ErgVulNQD/J5q8NWlBqFnZtZWfPhpZqXiUDOzUnGoDaLR0I2RTtJ1kn4raVXetRSRpPGS7pe0RtJqSefmXdNI4nNqAyRDN54BPkH1ZsBlwJyIWJNrYQUi6c+AV4HvRcRBeddTNJL2AvaKiBWSdgYeA/7Cf4eGh3tq75Zm6MaIFhEPUr0SZYOIiA0RsSJ5vRlYS/XOeBsGDrV3G2zohv9C2nuSzCpxKLAk30pGDoeaWYtIGgPcBpwXEa/kXc9I4VB7tzRDN8zqkjSKaqDdFBG3513PSOJQe7c0QzfMhpRMjXMtsDYiLsu7npHGoTZARGwD+odurAV+GBGr862qWCTdDPwCOEDSOkmfzbumgjkaOA34mKTHk2VW3kWNFL6lw8xKxT01MysVh5qZlYpDzcxKxaFmZqXiUDOzUnGojVCSjpF0d/L6xHqzkUjaTdLfvodt/B9J56f9fMA610s6OcO2JnjWEAOHWukks4xkEhF3RsT8OqvsBmQONbM8ONTaRNITeUrSTZLWSrpV0vuS716QdImkFcApkqZL+oWkFZJuScYg9s8T91Sy3l/WtH2GpCuT1/9Z0o8kPZEsRwHzgUnJTaSXJut9SdIySSslfb2mra9KekbSw8ABKX6vzyXtPCHptv7fKfFxScuT9j6ZrN8h6dKabf+P7d23Vi4OtfZyAPAvEfGnwCu8s/f0ckR8BPgpcAHw8eT9cuDvJO0IXAOcAHwU2HOIbVwBPBARHwY+AqwG5gG/iohDIuJLkqYD+1OdpukQ4KOS/kzSR6kOKzsEmAUcluJ3uj0iDku2txaoHZ0wIdnG8cDVye/wWWBTRByWtP85SRNTbMdGCD9Nqr28FBGPJK+/D5wDfDN5vyj58wigG3ikOgSR0VSHNB0IPB8RzwJI+j4wd5BtfAz4NEBE9AGbJO0+YJ3pyfLL5P0YqiG3M/CjiPhDso00Y2YPkvSPVA9xx1AdntbvhxHxJvCspOeS32E6cHDN+bZdk20/k2JbNgI41NrLwDFtte9fS/4UcF9EzKldUdIhTaxDwMUR8Z0B2zjvPbR1PdVZYZ+QdAZwTM13g/2+Av5nRNSGX/+8ZWY+/Gwz+0g6Mnn9KeDhQdZ5FDha0mQASe+X9EHgKWCCpEnJenMG+VmAnwFnJT/bIWlXYDPVXli/xcCZNefquiT9CfAg8BeSdkqmsT4hxe+0M7Ahmarnvw347hRJlaTm/YCnk22flayPpA9Ken+K7dgI4VBrL08DZ0taC+wOfHvgChHxO+AM4GZJK0kOPSPidaqHm/83uVDw2yG2cS7w55KepDq3fndEvEz1cHaVpEsj4ifAD4BfJOvdCuycTGG9CHgCuJfqNE6N/APVWWEfoRq8tX4NLE3a+nzyO3wXWAOsSG7h+A4+4rAanqWjTSSHV3f7QSdm9bmnZmal4p6amZWKe2pmVioONTMrFYeamZWKQ83MSsWhZmal8v8BUbk4PBPiVzoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXCs-U82tqq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "fffe2d20-b360-48a2-bbe6-8604c52c8c8e"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import interp\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Plot linewidth.\n",
        "lw = 2\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "n_classes = 3\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(ans2[:, i], Y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(ans2.ravel(), Y_pred.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# Compute macro-average ROC curve and ROC area\n",
        "\n",
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "plt.figure(1)\n",
        "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "#          label='micro-average ROC curve (area = {0:0.2f})'\n",
        "#                ''.format(roc_auc[\"micro\"]),\n",
        "#          color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = cycle(['hotpink', 'mediumslateblue', 'yellowgreen', 'deepskyblue', 'darkorange'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "plt.savefig('gdrive/My Drive/Colab Notebooks/cnn/model_data1000/roc-2.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}